{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "DistilBERT_kaggle_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Studiegruppe-TM/datascience_proj/blob/main/DistilBERT_kaggle_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inqEjMWz-Cth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ef8c96-130b-4f36-b347-51d174177bb3"
      },
      "source": [
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "#google halloej \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#list=[]\n",
        "#result = [list]\n",
        "#articles = '/content/drive/MyDrive/data science colab notesbooks/train.tsv'\n",
        "#for chunk in pd.read_csv(articles, chunksize=100, sep='\\t'):\n",
        "#  result.append(chunk)\n",
        "\n",
        "\n",
        "\n",
        "#total = sum(result)\n",
        "\n",
        "\n",
        "#articles = df_1.fillna('a')\n",
        "\n",
        "#zipfile = ZipFile(BytesIO(resp.read()))\n",
        "#articles = pd.read_csv(zipfile.open(zipfile.namelist()[0]))\n",
        "\n",
        "# Subset for faster processing\n",
        "\n"
      ],
      "id": "inqEjMWz-Cth",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xYkXFgjGExe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49d182c-550d-4b82-cbb7-9dee2e802008"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "7xYkXFgjGExe",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeBvnN2S66pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f3dd61-9e6f-47d9-f61f-92d21ce62834"
      },
      "source": [
        "#list=[]\n",
        "#result = [list]\n",
        "#articles = '/content/drive/MyDrive/data science colab notesbooks/train.tsv'\n",
        "#for chunk in pd.read_csv(articles, chunksize=1000,names=[]\n",
        "                                                         \n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "result = pd.read_json('/content/drive/MyDrive/data science colab notesbooks/test_set.json')\n",
        "train = pd.read_csv('/content/drive/MyDrive/data_science_rapport_august_2021/fakenews.csv')\n",
        "\n",
        "\n",
        "#train1 = []\n",
        "#for chunk in pd.read_csv('/content/drive/MyDrive/data_science_rapport_august_2021/FakeNewsCorpus_dataset/fakenews.csv')\n",
        " # chunksize=1000,names=['id', 'content']):\n",
        "#    train1.append(chunk)\n",
        "\n",
        "#articles = '/content/drive/MyDrive/data science colab notesbooks/train.tsv'\n",
        "#for chunk in pd.read_csv('/content/drive/MyDrive/data_science_rapport_august_2021/news_sample.csv', chunksize=1000, sep='\\t'):\n",
        "  #train1.append(chunk)\n",
        "\n",
        "\n",
        "#print(chunk)\n",
        "#train = df.concat([train1[0], train[1], train1[2], train1[3], train1[4], train1[5], train1[6], train1[7], train1[8], train1[9])\n",
        "\n",
        "result_1 = result.iloc[: 1000, 0:2]\n",
        "result_2 = result.iloc[1000: 2000, 0:2]\n",
        "result_3 = result.iloc[2000: 3000, 0:2]\n",
        "result_4 = result.iloc[3000: 4000, 0:2]\n",
        "result_5 = result.iloc[4000: 5000, 0:2]\n",
        "result_6 = result.iloc[5000: 6335, 0:2]\n",
        "\n",
        "train_1 = train.iloc[: 1000, 0:6]\n",
        "train_2 = train.iloc[1000: 2000, 0:6]\n",
        "train_3 = train.iloc[2000: 3000, 0:6]\n",
        "train_4 = train.iloc[3000: 4000, 0:6]\n",
        "train_5 = train.iloc[4000: 5000, 0:6]\n",
        "train_6 = train.iloc[5000: 6000, 0:6]\n",
        "train_7 = train.iloc[6000: 7000, 0:6]\n",
        "train_8 = train.iloc[7000: 8000, 0:6]\n",
        "train_9 = train.iloc[8000: 9000, 0:6]\n",
        "train_10 = train.iloc[9000: 1000, 0:6]\n",
        "\n",
        "print(train_1)"
      ],
      "id": "XeBvnN2S66pp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Unnamed: 0  ...                                            content\n",
            "0            0  ...  Life is an illusion, at least on a quantum lev...\n",
            "1            2  ...  The Los Angeles Police Department has been den...\n",
            "2            3  ...  The White House has decided to quietly withdra...\n",
            "3            5  ...  The Central American nation and six other stat...\n",
            "4            8  ...  “When the police finally left the campus, arou...\n",
            "..         ...  ...                                                ...\n",
            "995       3883  ...  Space exploration is an intriguing and necessa...\n",
            "996       3887  ...  FISA Documents Released\\n\\n% of readers think ...\n",
            "997       3891  ...  Elias Bejjani\\n\\nElias Bejjani , Chairman for ...\n",
            "998       3898  ...  Note:\\n\\nI do not necessarily endorse any prod...\n",
            "999       3900  ...  Epoch Times\\n\\nThe Epoch Times: \"A Fresh Look ...\n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxZRm5c4f2JI"
      },
      "source": [
        ""
      ],
      "id": "dxZRm5c4f2JI",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j8rq-sr-Ctm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2739946-0bff-4842-8ffb-2a8e7ac23992"
      },
      "source": [
        "print(result_1)\n"
      ],
      "id": "7j8rq-sr-Ctm",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id                                            article\n",
            "0     8476  Daniel Greenfield, a Shillman Journalism Fello...\n",
            "1    10294  Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
            "2     3608  U.S. Secretary of State John F. Kerry said Mon...\n",
            "3    10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
            "4      875  It's primary day in New York and front-runners...\n",
            "..     ...                                                ...\n",
            "995   8473  Clintons Are Under Multiple FBI Investigations...\n",
            "996   5606  Military: Goal Is to 'Liberate' Eastern Bank o...\n",
            "997   5753  SHOCK VIDEO : Hillary Needs Help Climbing ONE ...\n",
            "998   2775  President Obama’s decision to expand the U.S. ...\n",
            "999  10085  geoengineeringwatch.org \\nGlobal climate engin...\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkcFEW4dWf-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4f7ad3-3773-43ca-90bd-73e0a80f986a"
      },
      "source": [
        "#print(ubaad_new1) \n",
        "#print(ubaad_new2)\n",
        "\n",
        "\n",
        "t = range(0,200)\n",
        "pu = result_1\n",
        "\n",
        "import itertools\n",
        "\n",
        "correct_next_element = 1\n",
        "\n",
        "#skifte element i result[i] \n",
        "new_List = [range(2,10000)] # Vi er sgu ikke helt sikre på det her \n",
        "list_cycle = itertools.cycle(new_List)\n",
        "next(list_cycle)\n",
        "\n",
        "#for i in result:\n",
        "\n",
        "#Gammelt stuff\n",
        "   #print(pu['type'])\n",
        "   #pu['label'] = 'real'\n",
        "   #pu.loc[pu['type'] == 'fake', 'label'] = 'fake'\n",
        "   \n",
        "#Hvad vi definerer som korrekte labels\n",
        "#pu['1'] = 'fake'\n",
        "#pu.loc[pu[1] == 'real', 'label'] = 'real'\n",
        "#pu.loc[pu[1] == 'political', 'label'] = 'real'\n",
        "#pu.loc[pu[1] == 'reliable', 'label'] = 'real'\n",
        "\n",
        "#Andet gammelt stugff\n",
        "   #pu = result[w]\n",
        "   #pu2 = result[w + 1]\n",
        "\n",
        "#skifte element i result[i]\n",
        "   #next_element = next(list_cycle)\n",
        "   #print(next_element)\n",
        "   #correct_next_element = next_element\n",
        "   #print(correct_next_element)\n",
        "   \n",
        "   #pu = result[correct_next_element]\n",
        "   #print(pu)\n",
        "\n",
        "#print(result[2]['label'])\n",
        "\n",
        "\n"
      ],
      "id": "vkcFEW4dWf-7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(2, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Aa7jQE5cAZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0c7c03-4cbe-4bad-e2e8-4d7520e8f093"
      },
      "source": [
        "print(train_1['content'])"
      ],
      "id": "9Aa7jQE5cAZ9",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      Life is an illusion, at least on a quantum lev...\n",
            "1      The Los Angeles Police Department has been den...\n",
            "2      The White House has decided to quietly withdra...\n",
            "3      The Central American nation and six other stat...\n",
            "4      “When the police finally left the campus, arou...\n",
            "                             ...                        \n",
            "995    Space exploration is an intriguing and necessa...\n",
            "996    FISA Documents Released\\n\\n% of readers think ...\n",
            "997    Elias Bejjani\\n\\nElias Bejjani , Chairman for ...\n",
            "998    Note:\\n\\nI do not necessarily endorse any prod...\n",
            "999    Epoch Times\\n\\nThe Epoch Times: \"A Fresh Look ...\n",
            "Name: content, Length: 1000, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZD6Y9LD-Ctn"
      },
      "source": [
        "# **DistilBERT delen**"
      ],
      "id": "nZD6Y9LD-Ctn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FLpPzBp-Cto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7665ca77-3f4f-491a-ea36-6acd015dc91e"
      },
      "source": [
        "# Install the transformer package (the models used for creating the embeddings)\n",
        "!pip install transformers"
      ],
      "id": "-FLpPzBp-Cto",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRHpgTYr1pKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e875476c-f15d-4895-f11c-11de2d4bbed7"
      },
      "source": [
        "import transformers as ppb # pytorch transformers\n",
        "import torch\n",
        "\n",
        "# Create tokenizer and model input\n",
        "tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Switch to eval mode (rather than training mode) - this potentially gives a slight speedup\n",
        "model.eval()"
      ],
      "id": "zRHpgTYr1pKF",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertModel(\n",
              "  (embeddings): Embeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (layer): ModuleList(\n",
              "      (0): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (1): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (2): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (3): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (4): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (5): TransformerBlock(\n",
              "        (attention): MultiHeadSelfAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtk0lvDVDkcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4956f2-1b55-4292-f615-92161ad1e2ea"
      },
      "source": [
        "\n",
        "#Tokenize fake news data \n",
        "fakenews_train_tokenized1 = train_1['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized2 = train_2['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized3 = train_3['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized4 = train_4['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized5 = train_5['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized6 = train_6['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized7 = train_7['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized8 = train_8['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized9 = train_9['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "fakenews_train_tokenized10 = train_10['content'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "\n",
        "fake_t11 = fakenews_train_tokenized1.append(fakenews_train_tokenized2) #, tokenized2, tokenized3, tokenized4, tokenized5, tokenized6 )\n",
        "fake_t12 = fake_t11.append(fakenews_train_tokenized3)\n",
        "fake_t13 = fake_t12.append(fakenews_train_tokenized4)\n",
        "fake_t14 = fake_t13.append(fakenews_train_tokenized5)\n",
        "fakenews_train_tokenized = fake_t14.append(fakenews_train_tokenized6)\n",
        "\n",
        "\n",
        "# Pad input so that all sequences are of the same size:\n",
        "max_len = 0\n",
        "for i in fakenews_train_tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "fakenews_train_padded = np.array([i + [0]*(max_len-len(i)) for i in fakenews_train_tokenized.values])\n",
        "\n",
        "# Actually, we can only deal with sequence lengths up to 512 with the DistilBert model, so we'll just truncate \n",
        "fakenews_train_padded = fakenews_train_padded[:,:512]\n",
        "\n",
        "#splitte padded \n",
        "fakenews_train_padded = np.split(fakenews_train_padded,5)\n",
        "\n",
        "# Tell embedding model to disregard pad tokens\n",
        "fakenews_train_attention_mask1 = np.where(fakenews_train_padded[0] != 0, 1, 0)\n",
        "fakenews_train_attention_mask2 = np.where(fakenews_train_padded[1] != 0, 1, 0)\n",
        "fakenews_train_attention_mask3 = np.where(fakenews_train_padded[2] != 0, 1, 0)\n",
        "fakenews_train_attention_mask4 = np.where(fakenews_train_padded[3] != 0, 1, 0)\n",
        "fakenews_train_attention_mask5 = np.where(fakenews_train_padded[4] != 0, 1, 0)\n",
        "\n",
        "#print(padded.shape)\n",
        "#print(fakenews_train_padded)\n",
        "\n",
        "\n"
      ],
      "id": "Wtk0lvDVDkcZ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dCumnGx1sxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a67193-53c9-47a5-9cf1-aa3d4602f4b5"
      },
      "source": [
        "\n",
        "# Tokenize jsoninput\n",
        "tokenized1 = result_1['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized2 = result_2['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized3 = result_3['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized4 = result_4['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized5 = result_5['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized6 = result_6['article'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "t11 = tokenized1.append(tokenized2) #, tokenized2, tokenized3, tokenized4, tokenized5, tokenized6 )\n",
        "t12 = t11.append(tokenized3)\n",
        "t13 = t12.append(tokenized4)\n",
        "t14 = t13.append(tokenized5)\n",
        "tokenized = t14.append(tokenized6)\n",
        "\n",
        "\n",
        "# Pad input so that all sequences are of the same size:\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "# Actually, we can only deal with sequence lengths up to 512 with the DistilBert model, so we'll just truncate \n",
        "padded = padded[:,:512]\n",
        "\n",
        "#splitte padded \n",
        "padded = np.split(padded,5)\n",
        "\n",
        "# Tell embedding model to disregard pad tokens\n",
        "attention_mask1 = np.where(padded[0] != 0, 1, 0)\n",
        "attention_mask2 = np.where(padded[1] != 0, 1, 0)\n",
        "attention_mask3 = np.where(padded[2] != 0, 1, 0)\n",
        "attention_mask4 = np.where(padded[3] != 0, 1, 0)\n",
        "attention_mask5 = np.where(padded[4] != 0, 1, 0)\n",
        "\n",
        "#print(padded.shape)\n",
        "print(padded)"
      ],
      "id": "_dCumnGx1sxq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[  101,  3817, 26713, ..., 13102,  7895,  9243],\n",
            "       [  101,  8224,  9231, ...,  2054,  3047,  1999],\n",
            "       [  101,  1057,  1012, ..., 12603,  1012,  1524],\n",
            "       ...,\n",
            "       [  101,  2279, 25430, ...,     0,     0,     0],\n",
            "       [  101,  9042,  2343, ...,  2085,  2052,  2031],\n",
            "       [  101,  1037,  2280, ...,  1010,  1524,  2002]]), array([[  101,  6696,  4306, ...,     0,     0,     0],\n",
            "       [  101,  6866,  1024, ...,     0,     0,     0],\n",
            "       [  101,  6221,  8398, ...,  1012,  8398,  2409],\n",
            "       ...,\n",
            "       [  101,  6221,  8398, ...,  2097, 22088, 11368],\n",
            "       [  101,  2105,  1996, ...,  2742,  1010,  1996],\n",
            "       [  101,  2011,  2728, ...,  4321,  1999,  3146]]), array([[  101,  2017,  2442, ...,  8840, 12244,  9538],\n",
            "       [  101,  7262,  1024, ...,  1010,  5385,  2031],\n",
            "       [  101,  2007,  2062, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  2054,  2001, ...,  4613,  2097,  7901],\n",
            "       [  101,  2007,  3806, ...,  2040,  3818,  6274],\n",
            "       [  101,  6221,  8398, ...,  2266,  1997,  1996]]), array([[  101,  2062,  2084, ...,  2216, 25612, 10285],\n",
            "       [  101,  1996,  3928, ...,  1037,  2535,  2007],\n",
            "       [  101,  1996, 18172, ...,  1037,  2186,  1997],\n",
            "       ...,\n",
            "       [  101,  2625,  2084, ...,  1037,  4920,  2008],\n",
            "       [  101,  1002,  2603, ...,     0,     0,     0],\n",
            "       [  101, 24321,  2058, ...,     0,     0,     0]]), array([[  101, 17949,  2055, ...,     0,     0,     0],\n",
            "       [  101,  3522, 12629, ...,     0,     0,     0],\n",
            "       [  101,  6221,  8398, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  3424,  1011, ...,  2045,  2003,  2069],\n",
            "       [  101,  5587,  2483, ...,  2034,  2165,  2058],\n",
            "       [  101, 15333,  2497, ...,  2123,  1005,  1056]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG0PMydCrBuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63f81f7-12ed-4294-b3b8-3b3c758063e4"
      },
      "source": [
        "print(tokenized)"
      ],
      "id": "xG0PMydCrBuv",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       [101, 3817, 26713, 1010, 1037, 11895, 3363, 23...\n",
            "1       [101, 8224, 9231, 3334, 4355, 10667, 2290, 579...\n",
            "2       [101, 1057, 1012, 1055, 1012, 3187, 1997, 2110...\n",
            "3       [101, 1517, 10905, 26095, 2332, 1006, 1030, 10...\n",
            "4       [101, 2009, 1005, 1055, 3078, 2154, 1999, 2047...\n",
            "                              ...                        \n",
            "6330    [101, 1996, 2110, 2533, 2409, 1996, 3951, 2120...\n",
            "6331    [101, 1996, 1520, 1052, 1521, 1999, 13683, 232...\n",
            "6332    [101, 3424, 1011, 8398, 13337, 2024, 5906, 199...\n",
            "6333    [101, 5587, 2483, 19557, 3676, 1010, 11154, 15...\n",
            "6334    [101, 15333, 2497, 5747, 2003, 3402, 7866, 839...\n",
            "Name: article, Length: 6335, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EZ75NWNncWd"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "id": "1EZ75NWNncWd",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfNpY835whBg"
      },
      "source": [
        ""
      ],
      "id": "GfNpY835whBg",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeniIUJ_B4EW"
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "JeniIUJ_B4EW",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVdpwaFIz0zK"
      },
      "source": [
        ""
      ],
      "id": "hVdpwaFIz0zK",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vu7L2i_yk8q"
      },
      "source": [
        "#NUMMER 1 json \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(padded[0]), device=device)\n",
        "attention_mask = torch.tensor(attention_mask1, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "embeddings = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    embeddings.append(embedding)\n",
        "embeddings = torch.cat(embeddings)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "embeddings = embeddings.cpu().numpy()\n"
      ],
      "id": "7Vu7L2i_yk8q",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN8c_Kt2zGho"
      },
      "source": [
        "#NUMMER 2 json \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(padded[1]), device=device)\n",
        "attention_mask = torch.tensor(attention_mask2, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "embeddings2 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    embeddings2.append(embedding)\n",
        "embeddings2 = torch.cat(embeddings2)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "embeddings2 = embeddings2.cpu().numpy()\n"
      ],
      "id": "DN8c_Kt2zGho",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvVURCNvzQm8"
      },
      "source": [
        "#NUMMER 3 json \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(padded[2]), device=device)\n",
        "attention_mask = torch.tensor(attention_mask3, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "embeddings3 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    embeddings3.append(embedding)\n",
        "embeddings3 = torch.cat(embeddings3)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "embeddings3 = embeddings3.cpu().numpy()\n"
      ],
      "id": "LvVURCNvzQm8",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P36qSS9EzVFN"
      },
      "source": [
        "#NUMMER 4 json \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(padded[3]), device=device)\n",
        "attention_mask = torch.tensor(attention_mask4, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "embeddings4 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    embeddings4.append(embedding)\n",
        "embeddings4 = torch.cat(embeddings4)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "embeddings4 = embeddings4.cpu().numpy()"
      ],
      "id": "P36qSS9EzVFN",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo7eJPXKzYcG"
      },
      "source": [
        "#NUMMER 5 json \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(padded[4]), device=device)\n",
        "attention_mask = torch.tensor(attention_mask5, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "embeddings5 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    embeddings5.append(embedding)\n",
        "embeddings5 = torch.cat(embeddings5)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "embeddings5 = embeddings5.cpu().numpy()"
      ],
      "id": "Bo7eJPXKzYcG",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUPBqjZHEwt"
      },
      "source": [
        "#NUMMER 1 - FAKE NEWS TRAIN DATA \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(fakenews_train_padded[0]), device=device)\n",
        "attention_mask = torch.tensor(fakenews_train_attention_mask1, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "fakenews_train_embeddings1 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    fakenews_train_embeddings1.append(embedding)\n",
        "fakenews_train_embeddings1 = torch.cat(fakenews_train_embeddings1)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "fakenews_train_embeddings1 = fakenews_train_embeddings1.cpu().numpy()\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "bmUPBqjZHEwt",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DEjEoH74cUE"
      },
      "source": [
        "#NUMMER 2 - FAKE NEWS TRAIN DATA \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(fakenews_train_padded[1]), device=device)\n",
        "attention_mask = torch.tensor(fakenews_train_attention_mask2, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "fakenews_train_embeddings2 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    fakenews_train_embeddings2.append(embedding)\n",
        "fakenews_train_embeddings2= torch.cat(fakenews_train_embeddings2)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "fakenews_train_embeddings2 = fakenews_train_embeddings2.cpu().numpy()"
      ],
      "id": "1DEjEoH74cUE",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyE4Bsp549Xd"
      },
      "source": [
        "#NUMMER 3 - FAKE NEWS TRAIN DATA \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(fakenews_train_padded[2]), device=device)\n",
        "attention_mask = torch.tensor(fakenews_train_attention_mask3, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "fakenews_train_embeddings3 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    fakenews_train_embeddings3.append(embedding)\n",
        "fakenews_train_embeddings3= torch.cat(fakenews_train_embeddings3)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "fakenews_train_embeddings3 = fakenews_train_embeddings3.cpu().numpy()"
      ],
      "id": "nyE4Bsp549Xd",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIq4gWmI5GPz"
      },
      "source": [
        "#NUMMER 4 - FAKE NEWS TRAIN DATA \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(fakenews_train_padded[3]), device=device)\n",
        "attention_mask = torch.tensor(fakenews_train_attention_mask4, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "fakenews_train_embeddings4 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    fakenews_train_embeddings4.append(embedding)\n",
        "fakenews_train_embeddings4= torch.cat(fakenews_train_embeddings4)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "fakenews_train_embeddings4 = fakenews_train_embeddings4.cpu().numpy()"
      ],
      "id": "HIq4gWmI5GPz",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xdI2XWS5M3H"
      },
      "source": [
        "#NUMMER 5 - FAKE NEWS TRAIN DATA \n",
        "\n",
        "# Convert input to a pytorch tensor (so that it can be used as input for the embedding model)\n",
        "input = torch.tensor(np.array(fakenews_train_padded[4]), device=device)\n",
        "attention_mask = torch.tensor(fakenews_train_attention_mask5, device=device)\n",
        "\n",
        "# Embed sequences (processing in batches to avoid memory problems)\n",
        "batch_size= 200\n",
        "fakenews_train_embeddings5 = []\n",
        "for start_index in range(0, input.shape[0], batch_size):\n",
        "  with torch.no_grad():\n",
        "    # Call embedding model\n",
        "    embedding = model(input[start_index:start_index+batch_size], \n",
        "                      attention_mask=attention_mask[start_index:start_index+batch_size])[0][:,0,:]\n",
        "\n",
        "    fakenews_train_embeddings5.append(embedding)\n",
        "fakenews_train_embeddings5= torch.cat(fakenews_train_embeddings5)   # concatenate all batch outputs back into one tensor\n",
        "\n",
        "# Move embeddings back to numpy\n",
        "fakenews_train_embeddings5 = fakenews_train_embeddings5.cpu().numpy()"
      ],
      "id": "8xdI2XWS5M3H",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91jK6UoEb4ZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8f26ca64-5bc6-458c-c334-3af483e0de29"
      },
      "source": [
        "#json plot \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "embeddings = np.concatenate((embeddings, embeddings2, embeddings3, embeddings4, embeddings5))\n",
        "\n",
        "dim_reduced_embedding = pca.fit_transform(embeddings)#alle embedddings skal sættes sammen inden dette  \n",
        "plt.scatter(dim_reduced_embedding[:,0], dim_reduced_embedding[:,1])"
      ],
      "id": "91jK6UoEb4ZU",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faa1a3d3790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5acwVoOQ5eHA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dc99c9d2-6120-47e0-e535-ac1108222831"
      },
      "source": [
        "#fake news data plot\n",
        "\n",
        "fakenews_train_embeddings = np.concatenate((fakenews_train_embeddings1, fakenews_train_embeddings2, fakenews_train_embeddings3, fakenews_train_embeddings4, fakenews_train_embeddings5))\n",
        "\n",
        "dim_reduced_embedding = pca.fit_transform(fakenews_train_embeddings)#alle embedddings skal sættes sammen inden dette  \n",
        "plt.scatter(dim_reduced_embedding[:,0], dim_reduced_embedding[:,1])\n"
      ],
      "id": "5acwVoOQ5eHA",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7faa1a10c510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGENxUS5Mqjq"
      },
      "source": [
        "#print(dim_reduced_embedding[300][0])\n",
        "#print(len(dim_reduced_embedding))"
      ],
      "id": "KGENxUS5Mqjq",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wUnGZS_kgZ"
      },
      "source": [
        "#print(result)\n",
        "#print(result['embeddingvaerdi'])\n",
        "#result['embeddingvaerdi'] = 0.0"
      ],
      "id": "T2wUnGZS_kgZ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLoXNRUx7lzz"
      },
      "source": [
        "#Tilføje embedding værdi til datasæt \n",
        "#ivaerdi = 0\n",
        "#iivaerdi = 0\n",
        "\n",
        "#for i in range(0,6334):\n",
        "#  result['embeddingvaerdi'][ivaerdi] = (dim_reduced_embedding[iivaerdi][0].astype(float))\n",
        "\n",
        "#  ivaerdi = ivaerdi + 1\n",
        " # iivaerdi = iivaerdi + 1\n",
        "\n",
        "#for i in result:\n",
        " # result['embeddinvaerdi'][i] = dim_reduced_embedding[i][0].astype(float)\n",
        "\n",
        "#print(result['embeddingvaerdi'])"
      ],
      "id": "nLoXNRUx7lzz",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jziznP0J60iX"
      },
      "source": [
        "#Lave labels til json \n",
        "\n",
        "#threshold = 1 # This is the 75th percentile for median house values.\n",
        "\n",
        "\n",
        "\n",
        "#i2vaerdi = 0 \n",
        "#result['label'] = 'FAKE'\n",
        "\n",
        "#for i in range(0,6334):\n",
        "#  if result['embeddingvaerdi'][i] > 1:\n",
        "#     result['label'][i] = 'REAL' #True.astype(float) \n",
        "#  else:\n",
        "#     result['label'][i] = 'FAKE' #False.astype(float) \n",
        "#\n",
        "#  i2vaerdi = i2vaerdi + 1\n",
        "    \n"
      ],
      "id": "jziznP0J60iX",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF3d46mDCVTp"
      },
      "source": [
        "#print(result['LABEL'][4])\n",
        "#print(result['embeddingvaerdi'][i2vaerdi])\n",
        "#result.loc[result['label'] == 'REAL']\n",
        "\n",
        "#print(result)"
      ],
      "id": "WF3d46mDCVTp",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HlJzsiqUCs7"
      },
      "source": [
        "Generere csv fil: \n",
        "\n"
      ],
      "id": "8HlJzsiqUCs7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP7HWZD0UwZ5"
      },
      "source": [
        "#frames2 = (result['id'])\n",
        "\n",
        "#label_AND_id = result[['id',\n",
        " #                     'label']]\n",
        "\n",
        "#label_AND_id.(result['label'])\n",
        "\n",
        "#print(label_AND_id)\n",
        "#label_AND_id.to_csv(r'/content/drive/MyDrive/data_science_rapport_august_2021/csv_to_Kaggle', index = False)\n"
      ],
      "id": "fP7HWZD0UwZ5",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcRBgbB_LMVi"
      },
      "source": [
        "# labels til original fake news data fil \n",
        "\n",
        "train['label'] = 'FAKE'\n",
        "train.loc[train['type'] == 'real', 'label'] = 'REAL'\n",
        "train.loc[train['type'] == 'political', 'label'] = 'REAL'\n",
        "train.loc[train['type'] == 'reliable', 'label'] = 'REAL'\n",
        "\n",
        "# orginal værdi 5999 (ikke 6000):\n",
        "train = train.head(6000)\n"
      ],
      "id": "zcRBgbB_LMVi",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McJQFJIhbyfk"
      },
      "source": [
        "# SPLIT TRAIN TEST delen **bold text**"
      ],
      "id": "McJQFJIhbyfk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bvu4HE7eAOV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "sum_y_train = []\n",
        "sum_y_val = []\n",
        "sum_y_test = []\n"
      ],
      "id": "-bvu4HE7eAOV",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_CiXFHfJh8"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(\n",
        "#    fakenews_train_embeddings, fakenews_train_embeddings, train['label'], random_state=0)"
      ],
      "id": "Zq_CiXFHfJh8",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRbGqZ33hB6Y"
      },
      "source": [
        ""
      ],
      "id": "pRbGqZ33hB6Y",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H59qsMLfWlO"
      },
      "source": [
        "# Use the 40% test set to split further into test and validation set with 50/50 split\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, shuffle=True, stratify=y_test)\n",
        "\n",
        "\n",
        "\n",
        "#print(len(y_train))\n",
        "#print(len(y_val))\n",
        "#print(len(y_test))\n",
        "\n",
        "#sum_y_train.append(len(y_train))\n",
        "#sum_y_val.append(len(y_val))\n",
        "#sum_y_test.append(len(y_test))"
      ],
      "id": "6H59qsMLfWlO",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh2Qh8erfk99"
      },
      "source": [
        "#print(sum_y_train)\n",
        "#print(sum_y_val)\n",
        "#print(sum_y_test)"
      ],
      "id": "eh2Qh8erfk99",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0NNEKYOhxdY"
      },
      "source": [
        "#print( result[4]['type']) "
      ],
      "id": "C0NNEKYOhxdY",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCpF1H8rtj2G"
      },
      "source": [
        "#print(y_train)\n"
      ],
      "id": "hCpF1H8rtj2G",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LftZKHmQNA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f2f885-4f79-48ed-dbcb-655738c56ef0"
      },
      "source": [
        "print(train['label'])"
      ],
      "id": "5LftZKHmQNA0",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       FAKE\n",
            "1       FAKE\n",
            "2       FAKE\n",
            "3       FAKE\n",
            "4       FAKE\n",
            "        ... \n",
            "5995    FAKE\n",
            "5996    FAKE\n",
            "5997    FAKE\n",
            "5998    FAKE\n",
            "5999    FAKE\n",
            "Name: label, Length: 6000, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYwkJIFbfdHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8842183d-4e98-4efa-bcd8-d112c9bb8dd5"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the classifier classes\n",
        "svc = SVC(kernel='linear') # Linear reg\n",
        "\n",
        "# Fit the model\n",
        "X_train = fakenews_train_embeddings\n",
        "y_train = train['label']\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "X_test = embeddings\n",
        "svc_pred = svc.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "#print(\"svc accuracy:\" + str(accuracy_score(y_test,svc_pred)))\n",
        "\n",
        "print(svc_pred)\n"
      ],
      "id": "VYwkJIFbfdHw",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['FAKE' 'FAKE' 'REAL' ... 'FAKE' 'FAKE' 'REAL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBQ2L3FYRUI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c3b6a5-1aca-49a9-afd4-3e2fe835cadf"
      },
      "source": [
        "svc_pred.shape"
      ],
      "id": "dBQ2L3FYRUI6",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6335,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knt81H8ARsDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f705304-ce96-436d-c065-036bc81b7dca"
      },
      "source": [
        "#frames2 = (result['id'])\n",
        "\n",
        "label_AND_id = result[['id']]\n",
        "\n",
        "label_AND_id['label']=pd.Series(svc_pred)\n",
        "\n",
        "print(label_AND_id)\n",
        "label_AND_id.to_csv(r'/content/drive/MyDrive/data_science_rapport_august_2021/csv_KORREKTE2_to_Kaggle', index = False)"
      ],
      "id": "Knt81H8ARsDe",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         id label\n",
            "0      8476  FAKE\n",
            "1     10294  FAKE\n",
            "2      3608  REAL\n",
            "3     10142  FAKE\n",
            "4       875  REAL\n",
            "...     ...   ...\n",
            "6330   4490  REAL\n",
            "6331   8062  FAKE\n",
            "6332   8622  FAKE\n",
            "6333   4021  FAKE\n",
            "6334   4330  REAL\n",
            "\n",
            "[6335 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmhyTmSd0cjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "173d5a7d-526f-4158-c88f-ead777a92010"
      },
      "source": [
        "# muted nu (de to nedenunder):\n",
        "#from sklearn.metrics import precision_recall_fscore_support\n",
        "#print(precision_recall_fscore_support(y_test,svc_pred,zero_division='warn')) # noget her ser sjovt ud, virker ikke med 0 eller 1"
      ],
      "id": "UmhyTmSd0cjA",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-9589eb77b54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msvc_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# noget her ser sjovt ud, virker ikke med 0 eller 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN54yJMBFCOY",
        "outputId": "f2575803-4543-4546-cd68-03ce3a68e619"
      },
      "source": [
        "np.shape(label_AND_id)"
      ],
      "id": "PN54yJMBFCOY",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6335, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFKfkq5GFFW5"
      },
      "source": [
        ""
      ],
      "id": "TFKfkq5GFFW5",
      "execution_count": null,
      "outputs": []
    }
  ]
}